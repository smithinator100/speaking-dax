# Hybrid Pipeline: WhisperX â†’ Gentle

**â­â­â­ Best improvement for accuracy + convenience**

This hybrid pipeline combines the strengths of both WhisperX and Gentle to deliver the most accurate lip-sync viseme generation without requiring manual transcription.

## Why Use the Hybrid Pipeline?

| Approach | Accuracy | Convenience | Transcript Required |
|----------|----------|-------------|---------------------|
| Rhubarb only | âœ… Good (~85-90%) | â­â­â­ Excellent | âŒ No |
| WhisperX only | âœ…âœ… Very Good (~90-95%) | â­â­â­ Excellent | âŒ No (auto-generates) |
| Gentle only | âœ…âœ…âœ… Excellent (~95-98%) | â­ Poor | âœ… Yes (manual) |
| **Hybrid** | **âœ…âœ…âœ… Excellent (~95-98%)** | **â­â­â­ Excellent** | **âŒ No (auto-generates)** |

### The Hybrid Advantage

1. **WhisperX (Step 1)** - Auto-generates accurate transcripts
   - No manual transcription work needed
   - Supports 90+ languages
   - ~95-98% transcription accuracy

2. **Gentle (Step 2)** - Precise phoneme-level timing
   - Uses WhisperX's transcript
   - Superior timing precision (Â±10-20ms)
   - Best viseme alignment quality

**Result:** Maximum accuracy with zero manual transcription work!

## Quick Start

### Prerequisites

1. **Python 3.8+**
   ```bash
   python3 --version
   ```

2. **WhisperX**
   ```bash
   pip install whisperx
   ```

3. **Gentle**
   ```bash
   # Clone and install Gentle
   git clone https://github.com/lowerquality/gentle.git
   cd gentle
   ./install.sh
   
   # Set environment variable (add to ~/.zshrc or ~/.bashrc)
   export GENTLE_RESOURCES_ROOT="$(pwd)"
   ```

4. **ffmpeg**
   ```bash
   # macOS
   brew install ffmpeg
   
   # Ubuntu
   sudo apt-get install ffmpeg
   ```

### Usage

#### Basic Usage

```bash
# Generate viseme map from audio (auto-transcribes)
node lip-sync-libraries/hybrid/hybrid-to-viseme.js audio.mp3
```

This will:
1. Auto-transcribe the audio using WhisperX
2. Save the transcript to `audio_transcript.txt`
3. Run Gentle forced alignment
4. Output viseme map to `audio_visemes-hybrid.json`

#### Custom Output

```bash
node lip-sync-libraries/hybrid/hybrid-to-viseme.js audio.mp3 output.json
```

#### Advanced Options

```bash
# Use larger WhisperX model for better accuracy
node lip-sync-libraries/hybrid/hybrid-to-viseme.js audio.mp3 output.json --whisper-model large-v2

# Specify language for faster processing
node lip-sync-libraries/hybrid/hybrid-to-viseme.js audio.mp3 output.json --whisper-language en

# Use GPU acceleration (requires CUDA)
node lip-sync-libraries/hybrid/hybrid-to-viseme.js audio.mp3 output.json --whisper-device cuda

# Fast mode (less accurate but faster)
node lip-sync-libraries/hybrid/hybrid-to-viseme.js audio.mp3 output.json --gentle-fast

# Verbose output
node lip-sync-libraries/hybrid/hybrid-to-viseme.js audio.mp3 output.json --verbose
```

#### Full Options

```bash
WhisperX Options:
  --whisper-model <size>      Model: tiny, base, small, medium, large-v2 (default: base)
  --whisper-language <code>   Language code (e.g., en, es, fr) or auto (default: auto)
  --whisper-device <device>   Device: cpu or cuda (default: cpu)

Gentle Options:
  --gentle-fast               Use fast mode (less accurate, faster)
  --gentle-threads <n>        Number of threads (default: CPU count)

General Options:
  --no-save-transcript        Don't save transcript to file
  --transcript-path <path>    Custom transcript save path
  --keep-temp                 Keep temporary files
  --verbose                   Enable verbose logging
```

## How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HYBRID PIPELINE                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

     audio.mp3
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   STEP 1: WhisperX  â”‚  â±ï¸  ~10-20s for 1min audio
â”‚   - Transcription   â”‚
â”‚   - No manual work  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
  transcript.txt
  "Hello world..."
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   STEP 2: Gentle    â”‚  â±ï¸  ~30-45s for 1min audio
â”‚   - Forced align    â”‚
â”‚   - Precise timing  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   STEP 3: Convert   â”‚  â±ï¸  <1s
â”‚   - Phonemes        â”‚
â”‚   - To Visemes      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
  visemes.json
  [{ start: 0.0, end: 0.07, value: "X" }, ...]
```

**Total Time:** ~40-65 seconds per minute of audio

## Output Format

The hybrid pipeline generates the same JSON format as other tools, plus additional metadata:

```json
{
  "metadata": {
    "soundFile": "audio.mp3",
    "duration": 3.93,
    "transcript": "Hello world",
    "source": "hybrid-whisperx-gentle",
    "pipeline": {
      "step1": "WhisperX transcription",
      "step2": "Gentle forced alignment",
      "whisperModel": "base",
      "whisperLanguage": "en",
      "gentleConservative": true
    }
  },
  "mouthCues": [
    { "start": 0.00, "end": 0.07, "value": "X" },
    { "start": 0.07, "end": 0.16, "value": "C" },
    { "start": 0.16, "end": 0.30, "value": "B" }
  ]
}
```

## Use as a Module

```javascript
import { convertAudioToViseme } from './lip-sync-libraries/hybrid/hybrid-to-viseme.js';

const visemeData = await convertAudioToViseme('audio.mp3', 'visemes.json', {
  // WhisperX options
  whisperModel: 'base',           // Model size
  whisperLanguage: 'auto',        // Language or 'auto'
  whisperDevice: 'cpu',           // 'cpu' or 'cuda'
  whisperBatchSize: 16,
  whisperComputeType: 'float32',
  
  // Gentle options
  gentleConservative: true,       // More accurate (slower)
  gentleThreads: 8,               // Number of threads
  gentleDisfluency: false,        // Include uh, um, etc.
  
  // General options
  minDuration: 0.03,              // Min viseme duration (seconds)
  saveTranscript: true,           // Save transcript to file
  transcriptPath: 'custom.txt',   // Custom transcript path
  keepTempFiles: false,           // Keep temp files
  verbose: false                  // Verbose logging
});

console.log(`Generated ${visemeData.mouthCues.length} viseme cues`);
console.log(`Transcript: ${visemeData.metadata.transcript}`);
```

## Comparison with Other Approaches

### Speed

| Pipeline | Time (1 min audio) | Speed Rating |
|----------|-------------------|--------------|
| Rhubarb only | ~5-10s | âš¡âš¡âš¡ Fastest |
| WhisperX only | ~10-20s | âš¡âš¡ Very Fast |
| Gentle only | ~30-45s | âš¡ Moderate |
| **Hybrid** | **~40-65s** | **âš¡ Moderate** |

### Accuracy

| Pipeline | Phoneme Accuracy | Timing Precision | Overall |
|----------|------------------|------------------|---------|
| Rhubarb only | ~85-90% | Â±50ms | âœ… Good |
| WhisperX only | ~90-95% | Â±20-30ms | âœ…âœ… Very Good |
| Gentle only (w/ manual transcript) | ~95-98% | Â±10-20ms | âœ…âœ…âœ… Excellent |
| **Hybrid** | **~95-98%** | **Â±10-20ms** | **âœ…âœ…âœ… Excellent** |

### When to Use Each

**Use Rhubarb when:**
- âœ… Speed is critical
- âœ… Real-time processing needed
- âœ… Simple setup required

**Use WhisperX when:**
- âœ… Very good accuracy is sufficient
- âœ… Faster processing preferred
- âœ… GPU acceleration available

**Use Gentle only when:**
- âœ… You already have accurate transcripts
- âœ… Maximum precision required
- âœ… Manual transcription is acceptable

**Use Hybrid when:** â­ **RECOMMENDED**
- âœ… **Maximum accuracy needed**
- âœ… **No manual transcription available**
- âœ… **Production-quality results**
- âœ… **Best overall quality/convenience trade-off**

## Troubleshooting

### WhisperX Issues

**"WhisperX not installed"**
```bash
pip install whisperx
# Or with requirements file
pip install -r lip-sync-libraries/whisperx/requirements.txt
```

**"CUDA not available" (GPU)**
```bash
# Visit https://pytorch.org/get-started/locally/
# Install PyTorch with CUDA support for your version
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### Gentle Issues

**"Gentle resources path not set"**
```bash
# Set environment variable
export GENTLE_RESOURCES_ROOT=/path/to/gentle

# Add to shell profile for persistence
echo 'export GENTLE_RESOURCES_ROOT=/path/to/gentle' >> ~/.zshrc
source ~/.zshrc
```

**"align.py not found"**
```bash
# Verify Gentle installation
ls $GENTLE_RESOURCES_ROOT/align.py

# If missing, reinstall Gentle
cd gentle
./install.sh
```

### General Issues

**"ffmpeg not found"**
```bash
# macOS
brew install ffmpeg

# Ubuntu
sudo apt-get install ffmpeg
```

**Slow processing**
- Use smaller WhisperX model: `--whisper-model tiny`
- Use fast Gentle mode: `--gentle-fast`
- Enable GPU: `--whisper-device cuda`
- Increase threads: `--gentle-threads 8`

**Poor accuracy**
- Use larger WhisperX model: `--whisper-model large-v2`
- Use conservative Gentle mode (default)
- Ensure high-quality audio (clear, low noise)

## Performance Optimization

### For Speed

```bash
# Fastest configuration (slight accuracy trade-off)
node hybrid-to-viseme.js audio.mp3 \
  --whisper-model tiny \
  --gentle-fast \
  --gentle-threads 8
```

### For Accuracy

```bash
# Maximum accuracy (slower processing)
node hybrid-to-viseme.js audio.mp3 \
  --whisper-model large-v2 \
  --whisper-language en
```

### For GPU Acceleration

```bash
# Use GPU for WhisperX (requires CUDA)
node hybrid-to-viseme.js audio.mp3 \
  --whisper-device cuda \
  --whisper-model large-v2
```

## Batch Processing

Process multiple audio files:

```javascript
import { convertAudioToViseme } from './lip-sync-libraries/hybrid/hybrid-to-viseme.js';
import { promises as fs } from 'fs';
import path from 'path';

async function batchProcess(audioFiles) {
  const results = [];
  
  for (const audioFile of audioFiles) {
    const outputFile = audioFile.replace(/\.[^.]+$/, '_visemes-hybrid.json');
    
    try {
      console.log(`\nğŸ“‚ Processing: ${audioFile}`);
      
      const visemeData = await convertAudioToViseme(audioFile, outputFile, {
        whisperModel: 'base',
        gentleConservative: true,
        verbose: false
      });
      
      results.push({
        file: audioFile,
        success: true,
        cues: visemeData.mouthCues.length,
        duration: visemeData.metadata.duration,
        transcript: visemeData.metadata.transcript
      });
      
    } catch (error) {
      results.push({
        file: audioFile,
        success: false,
        error: error.message
      });
    }
  }
  
  return results;
}

// Usage
const files = ['audio1.mp3', 'audio2.mp3', 'audio3.mp3'];
const results = await batchProcess(files);

console.log('\nğŸ“Š Batch Processing Summary:');
results.forEach(r => {
  if (r.success) {
    console.log(`âœ… ${r.file}: ${r.cues} cues, ${r.duration.toFixed(2)}s`);
  } else {
    console.log(`âŒ ${r.file}: ${r.error}`);
  }
});
```

## Examples

### Example 1: Basic Usage

```bash
node lip-sync-libraries/hybrid/hybrid-to-viseme.js audio-samples/audio-sample-v1/audio-sample.mp3
```

Output:
```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸš€ HYBRID PIPELINE: WhisperX â†’ Gentle
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ Input:   audio-samples/audio-sample-v1/audio-sample.mp3
ğŸ“ Output:  audio-samples/audio-sample-v1/audio-sample_visemes-hybrid.json

Configuration:
  WhisperX Model:    base
  WhisperX Language: auto
  WhisperX Device:   cpu
  Gentle Threads:    8
  Gentle Mode:       Conservative (more accurate)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ STEP 1: WhisperX Transcription
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ” Running WhisperX transcription...
âœ… WhisperX transcription complete!
   Time: 12.3s
   Language: en
   Transcript length: 156 characters

ğŸ“„ Transcript:
   I am not interested in speech sounds as such, but in the possibilities of their use in music.

ğŸ’¾ Transcript saved to: audio-sample_transcript.txt

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¯ STEP 2: Gentle Forced Alignment
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ” Running Gentle forced aligner with transcript...
âœ… Gentle alignment complete!
   Time: 34.7s

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ—£ï¸  STEP 3: Phoneme to Viseme Conversion
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”„ Converting phonemes to visemes...
âœ… Viseme conversion complete!

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š PIPELINE SUMMARY
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â±ï¸  Total time:       47.0s
ğŸ“ Total viseme cues: 189
ğŸ“ Duration:          8.930s
ğŸ¤ Transcript:        "I am not interested in speech sounds as such, but in the..."
ğŸŒ Language:          en

ğŸ’¾ Output files:
   Visemes:    audio-sample_visemes-hybrid.json
   Transcript: audio-sample_transcript.txt

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ¨ SUCCESS! Hybrid pipeline complete.
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Example 2: Maximum Accuracy

```bash
node lip-sync-libraries/hybrid/hybrid-to-viseme.js \
  audio-samples/audio-sample-v1/audio-sample.mp3 \
  output.json \
  --whisper-model large-v2 \
  --whisper-language en
```

### Example 3: Fast Processing

```bash
node lip-sync-libraries/hybrid/hybrid-to-viseme.js \
  audio.mp3 \
  output.json \
  --whisper-model tiny \
  --gentle-fast
```

## Resources

- [WhisperX Documentation](https://github.com/m-bain/whisperX)
- [Gentle Documentation](https://github.com/lowerquality/gentle)
- [Rhubarb Viseme Reference](https://github.com/DanielSWolf/rhubarb-lip-sync)
- [ARPAbet Phoneme Set](http://www.speech.cs.cmu.edu/cgi-bin/cmudict)

## License

MIT

